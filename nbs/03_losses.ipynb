{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions\n",
    "\n",
    "> A set of custom loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from bioMONAI.core import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import sigmoid\n",
    "\n",
    "from monai.losses import SSIMLoss\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from fastai.vision.all import mse, mae, CrossEntropyLossFlat, Any\n",
    "\n",
    "from bioMONAI.metrics import FRCMetric, get_fourier_ring_correlations\n",
    "from bioMONAI.core import torchTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def MSELoss(\n",
    "    inp: Any,\n",
    "    targ: Any\n",
    "    ) -> torchTensor:\n",
    "    \n",
    "    return mse(inp, targ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def L1Loss(\n",
    "    inp: Any,\n",
    "    targ: Any\n",
    "    ) -> torchTensor:\n",
    "    \n",
    "    return mae(inp, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SSIMLoss\n",
       "\n",
       ">      SSIMLoss (spatial_dims:int, data_range:float=1.0,\n",
       ">                kernel_type:monai.metrics.regression.KernelType|str=gaussian,\n",
       ">                win_size:int|collections.abc.Sequence[int]=11,\n",
       ">                kernel_sigma:float|collections.abc.Sequence[float]=1.5,\n",
       ">                k1:float=0.01, k2:float=0.03,\n",
       ">                reduction:monai.utils.enums.LossReduction|str=mean)\n",
       "\n",
       "*Compute the loss function based on the Structural Similarity Index Measure (SSIM) Metric.\n",
       "\n",
       "For more info, visit\n",
       "    https://vicuesoft.com/glossary/term/ssim-ms-ssim/\n",
       "\n",
       "SSIM reference paper:\n",
       "    Wang, Zhou, et al. \"Image quality assessment: from error visibility to structural\n",
       "    similarity.\" IEEE transactions on image processing 13.4 (2004): 600-612.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SSIMLoss\n",
       "\n",
       ">      SSIMLoss (spatial_dims:int, data_range:float=1.0,\n",
       ">                kernel_type:monai.metrics.regression.KernelType|str=gaussian,\n",
       ">                win_size:int|collections.abc.Sequence[int]=11,\n",
       ">                kernel_sigma:float|collections.abc.Sequence[float]=1.5,\n",
       ">                k1:float=0.01, k2:float=0.03,\n",
       ">                reduction:monai.utils.enums.LossReduction|str=mean)\n",
       "\n",
       "*Compute the loss function based on the Structural Similarity Index Measure (SSIM) Metric.\n",
       "\n",
       "For more info, visit\n",
       "    https://vicuesoft.com/glossary/term/ssim-ms-ssim/\n",
       "\n",
       "SSIM reference paper:\n",
       "    Wang, Zhou, et al. \"Image quality assessment: from error visibility to structural\n",
       "    similarity.\" IEEE transactions on image processing 13.4 (2004): 600-612.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SSIMLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class CombinedLoss:\n",
    "    \"\"\"\n",
    "    CombinedLoss computes a weighted combination of SSIM, MSE, and MAE losses.\n",
    "\n",
    "    This class allows for the combination of three different loss functions:\n",
    "    Structural Similarity Index (SSIM), Mean Squared Error (MSE), and Mean Absolute Error (MAE).\n",
    "    The weights for MSE and MAE can be adjusted, and the weight for SSIM is automatically \n",
    "    calculated as the remaining weight.\n",
    "    \n",
    "    CombinedLoss reference paper:\n",
    "    Shah, Z. H., Müller, M., Hammer, B., Huser, T., & Schenck, W. (2022, July). \n",
    "    Impact of different loss functions on denoising of microscopic images. \n",
    "    In 2022 International Joint Conference on Neural Networks (IJCNN) (pp. 1-10). IEEE.\n",
    "    \"\"\"\n",
    "    def __init__(self, spatial_dims=2,  # Number of spatial dimensions (2 for 2D images, 3 for 3D images)\n",
    "                 mse_weight=0.33,       # Weight for the MSE loss component\n",
    "                 mae_weight=0.33,       # Weight for the MAE loss component\n",
    "                 ):\n",
    "        store_attr()\n",
    "        self.SSIM_loss = SSIMLoss(spatial_dims=spatial_dims)\n",
    "        self.MSE_loss = nn.MSELoss()\n",
    "        self.MAE_loss = nn.L1Loss()\n",
    "        \n",
    "    def __call__(self, pred, targ):\n",
    "        \"\"\"\n",
    "        Compute the combined loss.\n",
    "        \"\"\"\n",
    "        return (1 - self.mse_weight - self.mae_weight) * self.SSIM_loss(pred, targ) + self.mse_weight * self.MSE_loss(pred, targ) + self.mae_weight * self.MAE_loss(pred, targ)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MSSSIMLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Scale Structural Similarity (MSSSIM) Loss using MONAI's SSIMLoss as the base.\n",
    "    \"\"\"\n",
    "    def __init__(self, spatial_dims=2,      # Number of spatial dimensions (2 for 2D images, 3 for 3D images).\n",
    "                 window_size: int = 8,      # Size of the Gaussian filter for SSIM.\n",
    "                 sigma: float = 1.5,        # Standard deviation of the Gaussian filter.\n",
    "                 reduction: str = \"mean\",   # Specifies the reduction to apply to the output ('mean', 'sum', or 'none').\n",
    "                 levels: int = 3,           # Number of scales to use for MS-SSIM.\n",
    "                 weights=None,              # Weights to apply to each scale. If None, default values are used.\n",
    "                 ):\n",
    "        super(MSSSIMLoss, self).__init__()\n",
    "        self.ssim = SSIMLoss(spatial_dims, win_size=window_size, kernel_sigma=sigma, reduction=\"none\")\n",
    "        self.levels = levels\n",
    "        if weights is None:\n",
    "            # Default weights for 5 levels, typically used in MS-SSIM\n",
    "            self.weights = torch.FloatTensor([0.0448, 0.2856, 0.3001, 0.2363, 0.1333])\n",
    "        else:\n",
    "            self.weights = torch.FloatTensor(weights)\n",
    "        self.weights = self.weights[:levels]\n",
    "        self.reduction = reduction\n",
    "        self.spatial_dims = spatial_dims\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Ensure input tensors are the same size\n",
    "        if x.size() != y.size():\n",
    "            raise ValueError(\"Input images must have the same dimensions.\")\n",
    "        \n",
    "        # Make sure the weights match the number of levels\n",
    "        if len(self.weights) != self.levels:\n",
    "            raise ValueError(f\"Number of weights ({len(self.weights)}) must match the number of levels ({self.levels}).\")\n",
    "        \n",
    "        msssim_values = []\n",
    "        for i in range(self.levels):\n",
    "            # Compute SSIM at this scale\n",
    "            ssim_value = self.ssim(x, y)\n",
    "            msssim_values.append(ssim_value * self.weights[i])\n",
    "\n",
    "            # Downsample images for the next scale, except at the last scale\n",
    "            if i < self.levels - 1:\n",
    "                pool = F.avg_pool2d if self.spatial_dims == 2 else F.avg_pool3d\n",
    "                x = pool(x, kernel_size=2, stride=2)\n",
    "                y = pool(y, kernel_size=2, stride=2)\n",
    "\n",
    "        # Stack and sum weighted SSIM values from all scales\n",
    "        msssim = torch.stack(msssim_values, dim=0).sum(dim=0)/self.weights.sum()\n",
    "\n",
    "        # Apply reduction (mean or sum)\n",
    "        if self.reduction == \"mean\":\n",
    "            return msssim.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return msssim.sum()\n",
    "        else:\n",
    "            return msssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-ssim:  tensor(0.9686, device='cuda:0') \n",
      "ssim:  tensor(0.9949, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "msssim_loss = MSSSIMLoss(levels=3)\n",
    "ssim_loss = SSIMLoss(2)\n",
    "output = torch.rand(10, 3, 64, 64).cuda()  # Example output\n",
    "target = torch.rand(10, 3, 64, 64).cuda()  # Example target\n",
    "loss = msssim_loss(output, target)\n",
    "loss2 = ssim_loss(output,target)\n",
    "print(\"ms-ssim: \",loss, '\\nssim: ', loss2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MSSSIML1Loss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Scale Structural Similarity (MSSSIM) with Gaussian-weighted L1 Loss.\n",
    "    \n",
    "    Reference paper:\n",
    "    Zhao, H., Gallo, O., Frosio, I., & Kautz, J. (2016). \n",
    "    Loss functions for image restoration with neural networks. \n",
    "    IEEE Transactions on computational imaging, 3(1), 47-57.\n",
    "    \"\"\"\n",
    "    def __init__(self, spatial_dims=2, # Number of spatial dimensions.\n",
    "                 alpha: float = 0.025, #  Weighting factor between MS-SSIM and L1 loss.\n",
    "                 window_size: int = 8, # Size of the Gaussian filter for SSIM.\n",
    "                 sigma: float = 1.5, # Standard deviation of the Gaussian filter.\n",
    "                 reduction: str = \"mean\", # Specifies the reduction to apply to the output ('mean', 'sum', or 'none').\n",
    "                 levels: int = 3, # Number of scales to use for MS-SSIM.\n",
    "                 weights=None, # Weights to apply to each scale. If None, default values are used.\n",
    "                 ):\n",
    "        super(MSSSIML1Loss, self).__init__()\n",
    "        self.msssim = MSSSIMLoss(spatial_dims=spatial_dims, window_size=window_size, sigma=sigma, \n",
    "                                 reduction=\"none\", levels=levels, weights=weights)\n",
    "        store_attr()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Compute MSSSIM loss\n",
    "        msssim_loss = self.msssim(x, y)\n",
    "\n",
    "        # Compute L1 loss with Gaussian weighting\n",
    "        gaussian = self.get_gaussian_weight(x.size()).to(x.device)\n",
    "        l1_loss = F.l1_loss(x, y, reduction='none') * gaussian\n",
    "\n",
    "        # Adjust reduction to accommodate 3D\n",
    "        spatial_dims = tuple(range(1, x.ndim))  # Automatically handles 2D and 3D\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            l1_loss = l1_loss.mean(dim=spatial_dims)\n",
    "        elif self.reduction == \"sum\":\n",
    "            l1_loss = l1_loss.sum(dim=spatial_dims)\n",
    "\n",
    "        # Combine the two losses\n",
    "        combined_loss = self.alpha * msssim_loss + (1 - self.alpha) * l1_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return combined_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return combined_loss.sum()\n",
    "        else:\n",
    "            return combined_loss\n",
    "\n",
    "    def get_gaussian_weight(self, size):\n",
    "        \"\"\"Generate a Gaussian weight tensor based on input size.\"\"\"\n",
    "        batch_size, channels, *spatial_shape = size\n",
    "        spatial_dims = len(spatial_shape)\n",
    "        \n",
    "        if spatial_dims == 2:\n",
    "            width, height = spatial_shape\n",
    "            sigma = width / 6.0\n",
    "            x, y = torch.arange(width, dtype=torch.float32, device='cuda'), torch.arange(height, dtype=torch.float32, device='cuda')\n",
    "            center_x, center_y = (width - 1) / 2.0, (height - 1) / 2.0\n",
    "            x_grid, y_grid = torch.meshgrid(x, y, indexing='ij')\n",
    "            gaussian = torch.exp(-((x_grid - center_x)**2 + (y_grid - center_y)**2) / (2 * sigma**2))\n",
    "            gaussian /= gaussian.sum()\n",
    "            gaussian_weight = gaussian.view(1, 1, width, height).expand(batch_size, channels, -1, -1)\n",
    "\n",
    "        elif spatial_dims == 3:\n",
    "            depth, width, height = spatial_shape\n",
    "            sigma = width / 6.0\n",
    "            z = torch.arange(depth, dtype=torch.float32, device='cuda')\n",
    "            x = torch.arange(width, dtype=torch.float32, device='cuda')\n",
    "            y = torch.arange(height, dtype=torch.float32, device='cuda')\n",
    "            center_z, center_x, center_y = (depth - 1) / 2.0, (width - 1) / 2.0, (height - 1) / 2.0\n",
    "            z_grid, x_grid, y_grid = torch.meshgrid(z, x, y, indexing='ij')\n",
    "            gaussian = torch.exp(-((z_grid - center_z)**2 + (x_grid - center_x)**2 + (y_grid - center_y)**2) / (2 * sigma**2))\n",
    "            gaussian /= gaussian.sum()\n",
    "            gaussian_weight = gaussian.view(1, 1, depth, width, height).expand(batch_size, channels, -1, -1, -1)\n",
    "\n",
    "        return gaussian_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-ssim:  tensor(0.0250) \n",
      "ssim:  tensor(0.9955)\n"
     ]
    }
   ],
   "source": [
    "msssiml1_loss = MSSSIML1Loss(alpha=0.025, window_size=11, sigma=1.5, levels=3)\n",
    "input_image = torch.randn(4, 1, 128, 128)  # Batch of 4 grayscale images (1 channel)\n",
    "target_image = torch.randn(4, 1, 128, 128)\n",
    "\n",
    "# Compute MSSSIM + Gaussian-weighted L1 loss\n",
    "loss = msssiml1_loss(input_image, target_image)\n",
    "loss2 = ssim_loss(input_image, target_image)\n",
    "print(\"ms-ssim: \", loss, '\\nssim: ', loss2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MSSSIML2Loss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Scale Structural Similarity (MSSSIM) with Gaussian-weighted L2 Loss.\n",
    "\n",
    "    Reference paper:\n",
    "    Zhao, H., Gallo, O., Frosio, I., & Kautz, J. (2016). \n",
    "    Loss functions for image restoration with neural networks. \n",
    "    IEEE Transactions on computational imaging, 3(1), 47-57.    \n",
    "    \"\"\"\n",
    "    def __init__(self, spatial_dims=2, # Number of spatial dimensions.\n",
    "                 alpha: float = 0.1,# Weighting factor between MS-SSIM and L2 loss.\n",
    "                 window_size: int = 11,# Size of the Gaussian window for SSIM.\n",
    "                 sigma: float = 1.5,# Standard deviation of the Gaussian.\n",
    "                 reduction: str = \"mean\",# Specifies the reduction to apply to the output ('mean', 'sum', or 'none').\n",
    "                 levels: int = 3,# Number of scales to use for MS-SSIM.\n",
    "                 weights=None,# Weights to apply to each scale. If None, default values are used.\n",
    "                 ):\n",
    "        super(MSSSIML2Loss, self).__init__()\n",
    "        self.msssim = MSSSIMLoss(spatial_dims=spatial_dims, window_size=window_size, sigma=sigma, reduction=\"none\", levels=levels, weights=weights)\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "        self.window_size = window_size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Compute MSSSIM loss\n",
    "        msssim_loss = self.msssim(x, y)\n",
    "\n",
    "        # Compute L1 loss with Gaussian weighting\n",
    "        # Generate Gaussian kernel based on the input size\n",
    "        batch_size, _, height, width = x.size()\n",
    "        gaussian = self.get_gaussian_weight(x.size()).to(x.device)\n",
    "\n",
    "        # Apply the Gaussian kernel as a weight to the L1 loss\n",
    "        l2_loss = F.mse_loss(x, y, reduction='none')\n",
    "        l2_loss = l2_loss * gaussian\n",
    "\n",
    "        # Sum or average the L1 loss based on the reduction\n",
    "        if self.reduction == \"mean\":\n",
    "            l2_loss = l2_loss.mean(dim=(1, 2, 3))  # Reduce over all spatial dimensions\n",
    "        elif self.reduction == \"sum\":\n",
    "            l2_loss = l2_loss.sum(dim=(1, 2, 3))   # Sum over all spatial dimensions\n",
    "        else:\n",
    "            l2_loss = l2_loss  # No reduction if 'none' is specified\n",
    "\n",
    "        # Combine the two losses\n",
    "        combined_loss = self.alpha * msssim_loss + (1 - self.alpha) * l2_loss\n",
    "\n",
    "        # Apply final reduction to the combined loss\n",
    "        if self.reduction == \"mean\":\n",
    "            return combined_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return combined_loss.sum()\n",
    "        else:\n",
    "            return combined_loss\n",
    "        \n",
    "    def get_gaussian_weight(self, size):\n",
    "        \"\"\"Generate a Gaussian weight tensor based on input size.\"\"\"\n",
    "        batch_size, channels, width, height = size\n",
    "        sigma = width / 6.0  # Using width/6 as an approximate scale for sigma\n",
    "\n",
    "        x = torch.arange(width, dtype=torch.float32, device='cuda')\n",
    "        y = torch.arange(height, dtype=torch.float32, device='cuda')\n",
    "\n",
    "        # Handle even-sized patches by adjusting the center position calculation\n",
    "        center_x = (width - 1) / 2.0 if width % 2 == 1 else width / 2.0\n",
    "        center_y = (height - 1) / 2.0 if height % 2 == 1 else height / 2.0\n",
    "\n",
    "        # Explicitly pass the indexing argument\n",
    "        x_grid, y_grid = torch.meshgrid(x, y, indexing='ij')\n",
    "\n",
    "        gaussian = torch.exp(-((x_grid - center_x)**2 + (y_grid - center_y)**2) / (2 * sigma**2))\n",
    "        gaussian /= gaussian.sum()  # Normalize the Gaussian\n",
    "\n",
    "        gaussian_weight = gaussian.view(1, 1, width, height)\n",
    "        gaussian_weight = gaussian_weight.expand(batch_size, channels, -1, -1)\n",
    "        return gaussian_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0956, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "msssim_l2_loss = MSSSIML2Loss()\n",
    "output = torch.rand(10, 3, 64, 64).cuda()  # Example output with even dimensions\n",
    "target = torch.rand(10, 3, 64, 64).cuda()  # Example target with even dimensions\n",
    "loss = msssim_l2_loss(output, target)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossEntropy and Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrossEntropyLossFlat3D(CrossEntropyLossFlat):\n",
    "    \"Same as `nn.CrossEntropyLoss`, but flattens input and target for 3D inputs.\"\n",
    "    def __call__(self, \n",
    "        inp: torchTensor, # Predictions (e.g., NCDHW or similar format)\n",
    "        targ: torchTensor, # Targets\n",
    "        **kwargs\n",
    "    ) -> torchTensor:\n",
    "        \"Flatten spatial dimensions (DHW) and apply loss.\"\n",
    "        inp = inp.permute(0, 2, 3, 4, 1).contiguous()  # Move class axis to the end\n",
    "        targ = targ.contiguous()\n",
    "        if self.flatten:\n",
    "            inp = inp.view(-1, inp.shape[-1])\n",
    "            targ = targ.view(-1)\n",
    "        return self.func(inp, targ, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    DiceLoss computes the Sørensen–Dice coefficient loss, which is often used \n",
    "    for evaluating the performance of image segmentation algorithms.\n",
    "\n",
    "    The Dice coefficient is a measure of overlap between two samples. It ranges \n",
    "    from 0 (no overlap) to 1 (perfect overlap). The Dice loss is computed as \n",
    "    1 - Dice coefficient, so it ranges from 1 (no overlap) to 0 (perfect overlap).\n",
    "\n",
    "    Attributes:\n",
    "        smooth (float): A smoothing factor to avoid division by zero and ensure numerical stability.\n",
    "\n",
    "    Methods:\n",
    "        forward(inputs, targets):\n",
    "            Computes the Dice loss between the predicted probabilities (inputs) \n",
    "            and the ground truth (targets).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, smooth=1, # Smoothing factor to avoid division by zero\n",
    "                 ):\n",
    "\n",
    "        \"\"\"\n",
    "        Initializes the DiceLoss instance with a smoothing factor.\n",
    "\n",
    "        \"\"\"\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \n",
    "        # Make sure the inputs are probabilities\n",
    "        inputs = sigmoid(inputs)\n",
    "\n",
    "        # Flatten tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        # Calculate the intersection\n",
    "        intersection = (inputs * targets).sum()\n",
    "\n",
    "        # Compute Dice Coefficient\n",
    "        dice = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
    "\n",
    "        # Copmute dice loss\n",
    "        loss = 1 - dice\n",
    "\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs and targets must be equally dimensional tensors\n",
    "from torch import randn, randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Loss: 0.4982335567474365\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = randn((1, 1, 256, 256))  # Input\n",
    "targets = randint(0, 2, (1, 1, 256, 256)).float()  # Ground Truth\n",
    "\n",
    "# Initialize\n",
    "dice_loss = DiceLoss()\n",
    "\n",
    "# Compute loss\n",
    "loss = dice_loss(inputs, targets)\n",
    "print('Dice Loss:', loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Ring Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def FRCLoss(image1,# The first input image.\n",
    "            image2,# The second input image.\n",
    "            ):\n",
    "\n",
    "    \"\"\"\n",
    "    Compute the Fourier Ring Correlation (FRC) loss between two images.\n",
    "\n",
    "    Returns:\n",
    "        - torch.Tensor: The FRC loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    return (1 - FRCMetric(image1, image2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def FCRCutoff(image1,# The first input image.\n",
    "             image2,# The second input image.\n",
    "             ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the cutoff frequency at when Fourier ring correlation drops to 1/7.\n",
    "\n",
    "    Returns:\n",
    "        - float: The cutoff frequency.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get y and x coordinates\n",
    "    y, x = get_fourier_ring_correlations(image1, image2)\n",
    "\n",
    "    # x -> frequency   y -> correlation\n",
    "    x = x.numpy()\n",
    "    y = y.numpy()\n",
    "\n",
    "\n",
    "    # Exponential function to fit\n",
    "    def exponential_func(x, a, b, c):\n",
    "        return a * np.exp(-b * x) + c\n",
    "\n",
    "    # Make fit\n",
    "    params, _ = curve_fit(exponential_func, x, y, p0=[1, 1, 1])\n",
    "\n",
    "    # Get Cutoff requency at 1/7\n",
    "    cutoff_frequency = (exponential_func((1/7), *params))\n",
    "\n",
    "    return cutoff_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
