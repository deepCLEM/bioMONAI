{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: A set of custom loss functions\n",
    "output-file: losses.html\n",
    "title: Loss functions\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L29){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSELoss\n",
       "\n",
       ">      MSELoss (inp:Any, targ:Any)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L29){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSELoss\n",
       "\n",
       ">      MSELoss (inp:Any, targ:Any)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MSELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### L1Loss\n",
       "\n",
       ">      L1Loss (inp:Any, targ:Any)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### L1Loss\n",
       "\n",
       ">      L1Loss (inp:Any, targ:Any)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(L1Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SSIMLoss\n",
       "\n",
       ">      SSIMLoss (spatial_dims:int, data_range:float=1.0,\n",
       ">                kernel_type:monai.metrics.regression.KernelType|str=gaussian,\n",
       ">                win_size:int|collections.abc.Sequence[int]=11,\n",
       ">                kernel_sigma:float|collections.abc.Sequence[float]=1.5,\n",
       ">                k1:float=0.01, k2:float=0.03,\n",
       ">                reduction:monai.utils.enums.LossReduction|str=mean)\n",
       "\n",
       "*Compute the loss function based on the Structural Similarity Index Measure (SSIM) Metric.\n",
       "\n",
       "For more info, visit\n",
       "    https://vicuesoft.com/glossary/term/ssim-ms-ssim/\n",
       "\n",
       "SSIM reference paper:\n",
       "    Wang, Zhou, et al. \"Image quality assessment: from error visibility to structural\n",
       "    similarity.\" IEEE transactions on image processing 13.4 (2004): 600-612.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SSIMLoss\n",
       "\n",
       ">      SSIMLoss (spatial_dims:int, data_range:float=1.0,\n",
       ">                kernel_type:monai.metrics.regression.KernelType|str=gaussian,\n",
       ">                win_size:int|collections.abc.Sequence[int]=11,\n",
       ">                kernel_sigma:float|collections.abc.Sequence[float]=1.5,\n",
       ">                k1:float=0.01, k2:float=0.03,\n",
       ">                reduction:monai.utils.enums.LossReduction|str=mean)\n",
       "\n",
       "*Compute the loss function based on the Structural Similarity Index Measure (SSIM) Metric.\n",
       "\n",
       "For more info, visit\n",
       "    https://vicuesoft.com/glossary/term/ssim-ms-ssim/\n",
       "\n",
       "SSIM reference paper:\n",
       "    Wang, Zhou, et al. \"Image quality assessment: from error visibility to structural\n",
       "    similarity.\" IEEE transactions on image processing 13.4 (2004): 600-612.*"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SSIMLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CombinedLoss\n",
       "\n",
       ">      CombinedLoss (spatial_dims=2, mse_weight=0.33, mae_weight=0.33)\n",
       "\n",
       "*losses combined*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CombinedLoss\n",
       "\n",
       ">      CombinedLoss (spatial_dims=2, mse_weight=0.33, mae_weight=0.33)\n",
       "\n",
       "*losses combined*"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(CombinedLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L59){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIMLoss\n",
       "\n",
       ">      MSSSIMLoss (spatial_dims=2, window_size:int=8, sigma:float=1.5,\n",
       ">                  reduction:str='mean', levels:int=3, weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| spatial_dims | int | 2 | Number of spatial dimensions. |\n",
       "| window_size | int | 8 | Size of the Gaussian filter for SSIM. |\n",
       "| sigma | float | 1.5 | Standard deviation of the Gaussian filter. |\n",
       "| reduction | str | mean | Specifies the reduction to apply to the output ('mean', 'sum', or 'none'). |\n",
       "| levels | int | 3 | Number of scales to use for MS-SSIM. |\n",
       "| weights | NoneType | None | Weights to apply to each scale. If None, default values are used. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L59){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIMLoss\n",
       "\n",
       ">      MSSSIMLoss (spatial_dims=2, window_size:int=8, sigma:float=1.5,\n",
       ">                  reduction:str='mean', levels:int=3, weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| spatial_dims | int | 2 | Number of spatial dimensions. |\n",
       "| window_size | int | 8 | Size of the Gaussian filter for SSIM. |\n",
       "| sigma | float | 1.5 | Standard deviation of the Gaussian filter. |\n",
       "| reduction | str | mean | Specifies the reduction to apply to the output ('mean', 'sum', or 'none'). |\n",
       "| levels | int | 3 | Number of scales to use for MS-SSIM. |\n",
       "| weights | NoneType | None | Weights to apply to each scale. If None, default values are used. |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MSSSIMLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-ssim:  tensor(0.9686, device='cuda:0') \n",
      "ssim:  tensor(0.9949, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "msssim_loss = MSSSIMLoss(levels=3)\n",
    "ssim_loss = SSIMLoss(2)\n",
    "output = torch.rand(10, 3, 64, 64).cuda()  # Example output\n",
    "target = torch.rand(10, 3, 64, 64).cuda()  # Example target\n",
    "loss = msssim_loss(output, target)\n",
    "loss2 = ssim_loss(output,target)\n",
    "print(\"ms-ssim: \",loss, '\\nssim: ', loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L117){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIML1Loss\n",
       "\n",
       ">      MSSSIML1Loss (spatial_dims=2, alpha:float=0.025, window_size:int=8,\n",
       ">                    sigma:float=1.5, reduction:str='mean', levels:int=3,\n",
       ">                    weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| spatial_dims | int | 2 | Number of spatial dimensions. |\n",
       "| alpha | float | 0.025 | Weighting factor between MS-SSIM and L1 loss. |\n",
       "| window_size | int | 8 | Size of the Gaussian filter for SSIM. |\n",
       "| sigma | float | 1.5 | Standard deviation of the Gaussian filter. |\n",
       "| reduction | str | mean | Specifies the reduction to apply to the output ('mean', 'sum', or 'none'). |\n",
       "| levels | int | 3 | Number of scales to use for MS-SSIM. |\n",
       "| weights | NoneType | None | Weights to apply to each scale. If None, default values are used. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L117){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIML1Loss\n",
       "\n",
       ">      MSSSIML1Loss (spatial_dims=2, alpha:float=0.025, window_size:int=8,\n",
       ">                    sigma:float=1.5, reduction:str='mean', levels:int=3,\n",
       ">                    weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| spatial_dims | int | 2 | Number of spatial dimensions. |\n",
       "| alpha | float | 0.025 | Weighting factor between MS-SSIM and L1 loss. |\n",
       "| window_size | int | 8 | Size of the Gaussian filter for SSIM. |\n",
       "| sigma | float | 1.5 | Standard deviation of the Gaussian filter. |\n",
       "| reduction | str | mean | Specifies the reduction to apply to the output ('mean', 'sum', or 'none'). |\n",
       "| levels | int | 3 | Number of scales to use for MS-SSIM. |\n",
       "| weights | NoneType | None | Weights to apply to each scale. If None, default values are used. |"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MSSSIML1Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-ssim:  tensor(0.0250) \n",
      "ssim:  tensor(0.9955)\n"
     ]
    }
   ],
   "source": [
    "msssiml1_loss = MSSSIML1Loss(alpha=0.025, window_size=11, sigma=1.5, levels=3)\n",
    "input_image = torch.randn(4, 1, 128, 128)  # Batch of 4 grayscale images (1 channel)\n",
    "target_image = torch.randn(4, 1, 128, 128)\n",
    "\n",
    "# Compute MSSSIM + Gaussian-weighted L1 loss\n",
    "loss = msssiml1_loss(input_image, target_image)\n",
    "loss2 = ssim_loss(input_image, target_image)\n",
    "print(\"ms-ssim: \", loss, '\\nssim: ', loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L192){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIML2Loss\n",
       "\n",
       ">      MSSSIML2Loss (spatial_dims=2, alpha:float=0.1, window_size:int=11,\n",
       ">                    sigma:float=1.5, reduction:str='mean', levels:int=3,\n",
       ">                    weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| spatial_dims | int | 2 | Number of spatial dimensions. |\n",
       "| alpha | float | 0.1 | Weighting factor between MS-SSIM and L2 loss. |\n",
       "| window_size | int | 11 | Size of the Gaussian window for SSIM. |\n",
       "| sigma | float | 1.5 | Standard deviation of the Gaussian. |\n",
       "| reduction | str | mean | Specifies the reduction to apply to the output ('mean', 'sum', or 'none'). |\n",
       "| levels | int | 3 | Number of scales to use for MS-SSIM. |\n",
       "| weights | NoneType | None | Weights to apply to each scale. If None, default values are used. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L192){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIML2Loss\n",
       "\n",
       ">      MSSSIML2Loss (spatial_dims=2, alpha:float=0.1, window_size:int=11,\n",
       ">                    sigma:float=1.5, reduction:str='mean', levels:int=3,\n",
       ">                    weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| spatial_dims | int | 2 | Number of spatial dimensions. |\n",
       "| alpha | float | 0.1 | Weighting factor between MS-SSIM and L2 loss. |\n",
       "| window_size | int | 11 | Size of the Gaussian window for SSIM. |\n",
       "| sigma | float | 1.5 | Standard deviation of the Gaussian. |\n",
       "| reduction | str | mean | Specifies the reduction to apply to the output ('mean', 'sum', or 'none'). |\n",
       "| levels | int | 3 | Number of scales to use for MS-SSIM. |\n",
       "| weights | NoneType | None | Weights to apply to each scale. If None, default values are used. |"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MSSSIML2Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0956, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "msssim_l2_loss = MSSSIML2Loss()\n",
    "output = torch.rand(10, 3, 64, 64).cuda()  # Example output with even dimensions\n",
    "target = torch.rand(10, 3, 64, 64).cuda()  # Example target with even dimensions\n",
    "loss = msssim_l2_loss(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossEntropy and Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L267){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CrossEntropyLossFlat3D\n",
       "\n",
       ">      CrossEntropyLossFlat3D (*args, axis:int=-1, weight=None,\n",
       ">                              ignore_index=-100, reduction='mean',\n",
       ">                              flatten:bool=True, floatify:bool=False,\n",
       ">                              is_2d:bool=True)\n",
       "\n",
       "*Same as `nn.CrossEntropyLoss`, but flattens input and target for 3D inputs.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L267){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CrossEntropyLossFlat3D\n",
       "\n",
       ">      CrossEntropyLossFlat3D (*args, axis:int=-1, weight=None,\n",
       ">                              ignore_index=-100, reduction='mean',\n",
       ">                              flatten:bool=True, floatify:bool=False,\n",
       ">                              is_2d:bool=True)\n",
       "\n",
       "*Same as `nn.CrossEntropyLoss`, but flattens input and target for 3D inputs.*"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(CrossEntropyLossFlat3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L283){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DiceLoss\n",
       "\n",
       ">      DiceLoss (smooth=1)\n",
       "\n",
       "*DiceLoss computes the Sørensen–Dice coefficient loss, which is often used \n",
       "for evaluating the performance of image segmentation algorithms.\n",
       "\n",
       "The Dice coefficient is a measure of overlap between two samples. It ranges \n",
       "from 0 (no overlap) to 1 (perfect overlap). The Dice loss is computed as \n",
       "1 - Dice coefficient, so it ranges from 1 (no overlap) to 0 (perfect overlap).\n",
       "\n",
       "Attributes:\n",
       "    smooth (float): A smoothing factor to avoid division by zero and ensure numerical stability.\n",
       "\n",
       "Methods:\n",
       "    forward(inputs, targets):\n",
       "        Computes the Dice loss between the predicted probabilities (inputs) \n",
       "        and the ground truth (targets).*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| smooth | int | 1 | Smoothing factor to avoid division by zero |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L283){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DiceLoss\n",
       "\n",
       ">      DiceLoss (smooth=1)\n",
       "\n",
       "*DiceLoss computes the Sørensen–Dice coefficient loss, which is often used \n",
       "for evaluating the performance of image segmentation algorithms.\n",
       "\n",
       "The Dice coefficient is a measure of overlap between two samples. It ranges \n",
       "from 0 (no overlap) to 1 (perfect overlap). The Dice loss is computed as \n",
       "1 - Dice coefficient, so it ranges from 1 (no overlap) to 0 (perfect overlap).\n",
       "\n",
       "Attributes:\n",
       "    smooth (float): A smoothing factor to avoid division by zero and ensure numerical stability.\n",
       "\n",
       "Methods:\n",
       "    forward(inputs, targets):\n",
       "        Computes the Dice loss between the predicted probabilities (inputs) \n",
       "        and the ground truth (targets).*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| smooth | int | 1 | Smoothing factor to avoid division by zero |"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(DiceLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# inputs and targets must be equally dimensional tensors\n",
    "from torch import randn, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Loss: 0.4982335567474365\n"
     ]
    }
   ],
   "source": [
    "inputs = randn((1, 1, 256, 256))  # Input\n",
    "targets = randint(0, 2, (1, 1, 256, 256)).float()  # Ground Truth\n",
    "\n",
    "# Initialize\n",
    "dice_loss = DiceLoss()\n",
    "\n",
    "# Compute loss\n",
    "loss = dice_loss(inputs, targets)\n",
    "print('Dice Loss:', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Ring Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L334){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FRCLoss\n",
       "\n",
       ">      FRCLoss (image1, image2)\n",
       "\n",
       "*Compute the Fourier Ring Correlation (FRC) loss between two images.\n",
       "\n",
       "Returns:\n",
       "    - torch.Tensor: The FRC loss.*\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| image1 | The first input image. |\n",
       "| image2 | The second input image. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L334){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FRCLoss\n",
       "\n",
       ">      FRCLoss (image1, image2)\n",
       "\n",
       "*Compute the Fourier Ring Correlation (FRC) loss between two images.\n",
       "\n",
       "Returns:\n",
       "    - torch.Tensor: The FRC loss.*\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| image1 | The first input image. |\n",
       "| image2 | The second input image. |"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(FRCLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L349){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FCRCutoff\n",
       "\n",
       ">      FCRCutoff (image1, image2)\n",
       "\n",
       "*Calculate the cutoff frequency at when Fourier ring correlation drops to 1/7.\n",
       "\n",
       "Returns:\n",
       "    - float: The cutoff frequency.*\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| image1 | The first input image. |\n",
       "| image2 | The second input image. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/losses.py#L349){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FCRCutoff\n",
       "\n",
       ">      FCRCutoff (image1, image2)\n",
       "\n",
       "*Calculate the cutoff frequency at when Fourier ring correlation drops to 1/7.\n",
       "\n",
       "Returns:\n",
       "    - float: The cutoff frequency.*\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| image1 | The first input image. |\n",
       "| image2 | The second input image. |"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(FCRCutoff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
