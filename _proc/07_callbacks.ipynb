{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Event handlers\n",
    "output-file: callbacks.html\n",
    "title: Callbacks\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Callbacks\n",
    "\n",
    "Callbacks that add functionlities during the training phase, including Callbacks that make decisions depending how a monitored metric/loss behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/callbacks.py#L17){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MeanLossGraphCallback\n",
       "\n",
       ">      MeanLossGraphCallback (after_create=None, before_fit=None,\n",
       ">                             before_epoch=None, before_train=None,\n",
       ">                             before_batch=None, after_pred=None,\n",
       ">                             after_loss=None, before_backward=None,\n",
       ">                             after_cancel_backward=None, after_backward=None,\n",
       ">                             before_step=None, after_cancel_step=None,\n",
       ">                             after_step=None, after_cancel_batch=None,\n",
       ">                             after_batch=None, after_cancel_train=None,\n",
       ">                             after_train=None, before_validate=None,\n",
       ">                             after_cancel_validate=None, after_validate=None,\n",
       ">                             after_cancel_epoch=None, after_epoch=None,\n",
       ">                             after_cancel_fit=None, after_fit=None)\n",
       "\n",
       "*Update a graph of training and validation loss*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/callbacks.py#L17){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MeanLossGraphCallback\n",
       "\n",
       ">      MeanLossGraphCallback (after_create=None, before_fit=None,\n",
       ">                             before_epoch=None, before_train=None,\n",
       ">                             before_batch=None, after_pred=None,\n",
       ">                             after_loss=None, before_backward=None,\n",
       ">                             after_cancel_backward=None, after_backward=None,\n",
       ">                             before_step=None, after_cancel_step=None,\n",
       ">                             after_step=None, after_cancel_batch=None,\n",
       ">                             after_batch=None, after_cancel_train=None,\n",
       ">                             after_train=None, before_validate=None,\n",
       ">                             after_cancel_validate=None, after_validate=None,\n",
       ">                             after_cancel_epoch=None, after_epoch=None,\n",
       ">                             after_cancel_fit=None, after_fit=None)\n",
       "\n",
       "*Update a graph of training and validation loss*"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MeanLossGraphCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ShortEpochCallback\n",
       "\n",
       ">      ShortEpochCallback (pct=0.01, short_valid=True)\n",
       "\n",
       "*Fit just `pct` of an epoch, then stop*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ShortEpochCallback\n",
       "\n",
       ">      ShortEpochCallback (pct=0.01, short_valid=True)\n",
       "\n",
       "*Fit just `pct` of an epoch, then stop*"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ShortEpochCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GradientAccumulation\n",
       "\n",
       ">      GradientAccumulation (n_acc=32)\n",
       "\n",
       "*Accumulate gradients before updating weights*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GradientAccumulation\n",
       "\n",
       ">      GradientAccumulation (n_acc=32)\n",
       "\n",
       "*Accumulate gradients before updating weights*"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(GradientAccumulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EarlyStoppingCallback\n",
       "\n",
       ">      EarlyStoppingCallback (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                             patience=1, reset_on_fit=True)\n",
       "\n",
       "*A `TrackerCallback` that terminates training when monitored quantity stops improving.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| patience | int | 1 | number of epochs to wait when training has not improved model. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EarlyStoppingCallback\n",
       "\n",
       ">      EarlyStoppingCallback (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                             patience=1, reset_on_fit=True)\n",
       "\n",
       "*A `TrackerCallback` that terminates training when monitored quantity stops improving.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| patience | int | 1 | number of epochs to wait when training has not improved model. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(EarlyStoppingCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SaveModelCallback\n",
       "\n",
       ">      SaveModelCallback (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                         fname='model', every_epoch=False, at_end=False,\n",
       ">                         with_opt=False, reset_on_fit=True)\n",
       "\n",
       "*A `TrackerCallback` that saves the model's best during training and loads it at the end.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| fname | str | model | model name to be used when saving model. |\n",
       "| every_epoch | bool | False | if true, save model after every epoch; else save only when model is better than existing best. |\n",
       "| at_end | bool | False | if true, save model when training ends; else load best model if there is only one saved model. |\n",
       "| with_opt | bool | False | if true, save optimizer state (if any available) when saving model. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SaveModelCallback\n",
       "\n",
       ">      SaveModelCallback (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                         fname='model', every_epoch=False, at_end=False,\n",
       ">                         with_opt=False, reset_on_fit=True)\n",
       "\n",
       "*A `TrackerCallback` that saves the model's best during training and loads it at the end.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| fname | str | model | model name to be used when saving model. |\n",
       "| every_epoch | bool | False | if true, save model after every epoch; else save only when model is better than existing best. |\n",
       "| at_end | bool | False | if true, save model when training ends; else load best model if there is only one saved model. |\n",
       "| with_opt | bool | False | if true, save optimizer state (if any available) when saving model. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SaveModelCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ReduceLROnPlateau\n",
       "\n",
       ">      ReduceLROnPlateau (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                         patience=1, factor=10.0, min_lr=0, reset_on_fit=True)\n",
       "\n",
       "*A `TrackerCallback` that reduces learning rate when a metric has stopped improving.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| patience | int | 1 | number of epochs to wait when training has not improved model. |\n",
       "| factor | float | 10.0 | the denominator to divide the learning rate by, when reducing the learning rate. |\n",
       "| min_lr | int | 0 | the minimum learning rate allowed; learning rate cannot be reduced below this minimum. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ReduceLROnPlateau\n",
       "\n",
       ">      ReduceLROnPlateau (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                         patience=1, factor=10.0, min_lr=0, reset_on_fit=True)\n",
       "\n",
       "*A `TrackerCallback` that reduces learning rate when a metric has stopped improving.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| patience | int | 1 | number of epochs to wait when training has not improved model. |\n",
       "| factor | float | 10.0 | the denominator to divide the learning rate by, when reducing the learning rate. |\n",
       "| min_lr | int | 0 | the minimum learning rate allowed; learning rate cannot be reduced below this minimum. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ReduceLROnPlateau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedulers\n",
    "\n",
    "Callback and helper functions to schedule hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ParamScheduler\n",
       "\n",
       ">      ParamScheduler (scheds)\n",
       "\n",
       "*Schedule hyper-parameters according to `scheds`*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ParamScheduler\n",
       "\n",
       ">      ParamScheduler (scheds)\n",
       "\n",
       "*Schedule hyper-parameters according to `scheds`*"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ParamScheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scheds` is a dictionary with one key for each hyper-parameter you want to schedule, with either a scheduler or a list of schedulers as values (in the second case, the list must have the same length as the the number of parameters groups of the optimizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedCos\n",
       "\n",
       ">      SchedCos (start, end)\n",
       "\n",
       "*Cosine schedule function from `start` to `end`*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedCos\n",
       "\n",
       ">      SchedCos (start, end)\n",
       "\n",
       "*Cosine schedule function from `start` to `end`*"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SchedCos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedExp\n",
       "\n",
       ">      SchedExp (start, end)\n",
       "\n",
       "*Exponential schedule function from `start` to `end`*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedExp\n",
       "\n",
       ">      SchedExp (start, end)\n",
       "\n",
       "*Exponential schedule function from `start` to `end`*"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SchedExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedLin\n",
       "\n",
       ">      SchedLin (start, end)\n",
       "\n",
       "*Linear schedule function from `start` to `end`*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedLin\n",
       "\n",
       ">      SchedLin (start, end)\n",
       "\n",
       "*Linear schedule function from `start` to `end`*"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SchedLin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedNo\n",
       "\n",
       ">      SchedNo (start, end)\n",
       "\n",
       "*Constant schedule function with `start` value*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedNo\n",
       "\n",
       ">      SchedNo (start, end)\n",
       "\n",
       "*Constant schedule function with `start` value*"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SchedNo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
