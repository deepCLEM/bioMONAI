{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Download and store datasets\n",
    "output-file: datasets.html\n",
    "title: Datasets\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MedMNIST Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### download_medmnist\n",
       "\n",
       ">      download_medmnist (dataset:str, output_dir:str='.',\n",
       ">                         download_only:bool=False, save_images:bool=True)\n",
       "\n",
       "Downloads the specified MedMNIST dataset and saves the training, validation, and test datasets \n",
       "into the specified output directory. Images are saved as .png for 2D data and multi-page .tiff for 3D data,\n",
       "organized into folders named after their labels.\n",
       "\n",
       "Returns: None, saves images in the specified output directory if save_images is True.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| dataset | str |  | The name of the MedMNIST dataset (e.g., 'pathmnist', 'bloodmnist', etc.). |\n",
       "| output_dir | str | . | The path to the directory where the datasets will be saved. |\n",
       "| download_only | bool | False | If True, only download the dataset into the output directory without processing. |\n",
       "| save_images | bool | True | If True, save the images into the output directory as .png (2D datasets) or multipage .tiff (3D datasets) files. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### download_medmnist\n",
       "\n",
       ">      download_medmnist (dataset:str, output_dir:str='.',\n",
       ">                         download_only:bool=False, save_images:bool=True)\n",
       "\n",
       "Downloads the specified MedMNIST dataset and saves the training, validation, and test datasets \n",
       "into the specified output directory. Images are saved as .png for 2D data and multi-page .tiff for 3D data,\n",
       "organized into folders named after their labels.\n",
       "\n",
       "Returns: None, saves images in the specified output directory if save_images is True.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| dataset | str |  | The name of the MedMNIST dataset (e.g., 'pathmnist', 'bloodmnist', etc.). |\n",
       "| output_dir | str | . | The path to the directory where the datasets will be saved. |\n",
       "| download_only | bool | False | If True, only download the dataset into the output directory without processing. |\n",
       "| save_images | bool | True | If True, save the images into the output directory as .png (2D datasets) or multipage .tiff (3D datasets) files. |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(download_medmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### medmnist2df\n",
       "\n",
       ">      medmnist2df (train_dataset, val_dataset=None, test_dataset=None,\n",
       ">                   mode='RGB')\n",
       "\n",
       "Convert MedMNIST datasets to DataFrames, with images as PIL Image objects and labels as DataFrame columns.\n",
       "\n",
       "Missing datasets (if None) are represented by None in the return tuple.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| train_dataset |  |  | MedMNIST training dataset with images and labels |\n",
       "| val_dataset | NoneType | None | (Optional) MedMNIST validation dataset with images and labels |\n",
       "| test_dataset | NoneType | None | (Optional) MedMNIST test dataset with images and labels |\n",
       "| mode | str | RGB | Mode for PIL Image conversion, e.g., 'RGB', 'L' |\n",
       "| **Returns** | **(<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>)** |  | **(df_train, df_val, df_test): DataFrames with columns 'image' and 'label'** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### medmnist2df\n",
       "\n",
       ">      medmnist2df (train_dataset, val_dataset=None, test_dataset=None,\n",
       ">                   mode='RGB')\n",
       "\n",
       "Convert MedMNIST datasets to DataFrames, with images as PIL Image objects and labels as DataFrame columns.\n",
       "\n",
       "Missing datasets (if None) are represented by None in the return tuple.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| train_dataset |  |  | MedMNIST training dataset with images and labels |\n",
       "| val_dataset | NoneType | None | (Optional) MedMNIST validation dataset with images and labels |\n",
       "| test_dataset | NoneType | None | (Optional) MedMNIST test dataset with images and labels |\n",
       "| mode | str | RGB | Mode for PIL Image conversion, e.g., 'RGB', 'L' |\n",
       "| **Returns** | **(<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>)** |  | **(df_train, df_val, df_test): DataFrames with columns 'image' and 'label'** |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(medmnist2df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data via Pooch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### download_file\n",
       "\n",
       ">      download_file (url, output_dir='data', extract=True, hash=None,\n",
       ">                     extract_dir=None)\n",
       "\n",
       "Download and optionally decompress a single file using Pooch.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| url |  |  | The URL of the file to be downloaded |\n",
       "| output_dir | str | data | The directory where the downloaded file will be saved |\n",
       "| extract | bool | True | If True, decompresses the file if it's in a compressed format |\n",
       "| hash | NoneType | None | Optional: You can add a checksum for integrity verification |\n",
       "| extract_dir | NoneType | None | Directory to extract the files to |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### download_file\n",
       "\n",
       ">      download_file (url, output_dir='data', extract=True, hash=None,\n",
       ">                     extract_dir=None)\n",
       "\n",
       "Download and optionally decompress a single file using Pooch.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| url |  |  | The URL of the file to be downloaded |\n",
       "| output_dir | str | data | The directory where the downloaded file will be saved |\n",
       "| extract | bool | True | If True, decompresses the file if it's in a compressed format |\n",
       "| hash | NoneType | None | Optional: You can add a checksum for integrity verification |\n",
       "| extract_dir | NoneType | None | Directory to extract the files to |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(download_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### download_dataset\n",
       "\n",
       ">      download_dataset (base_url, expected_checksums, file_names, output_dir,\n",
       ">                        processor=None)\n",
       "\n",
       "Download a dataset using Pooch and save it to the specified output directory.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| base_url |  |  | The base URL from which the files will be downloaded. |\n",
       "| expected_checksums |  |  | A dictionary mapping file names to their expected checksums. |\n",
       "| file_names |  |  | A dictionary mapping task identifiers to file names. |\n",
       "| output_dir |  |  | The directory where the downloaded files will be saved. |\n",
       "| processor | NoneType | None | A function to process the downloaded data. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### download_dataset\n",
       "\n",
       ">      download_dataset (base_url, expected_checksums, file_names, output_dir,\n",
       ">                        processor=None)\n",
       "\n",
       "Download a dataset using Pooch and save it to the specified output directory.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| base_url |  |  | The base URL from which the files will be downloaded. |\n",
       "| expected_checksums |  |  | A dictionary mapping file names to their expected checksums. |\n",
       "| file_names |  |  | A dictionary mapping task identifiers to file names. |\n",
       "| output_dir |  |  | The directory where the downloaded files will be saved. |\n",
       "| processor | NoneType | None | A function to process the downloaded data. |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(download_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### download_dataset_from_csv\n",
       "\n",
       ">      download_dataset_from_csv (csv_file, base_url, output_dir,\n",
       ">                                 processor=None, rows=None, prepend_mdf5=True)\n",
       "\n",
       "Download a dataset using Pooch and save it to the specified output directory, reading file names and checksums from a CSV file.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| csv_file |  |  | Path to the CSV file containing file names and checksums. |\n",
       "| base_url |  |  | The base URL from which the files will be downloaded. |\n",
       "| output_dir |  |  | The directory where the downloaded files will be saved. |\n",
       "| processor | NoneType | None | A function to process the downloaded data. |\n",
       "| rows | NoneType | None | Specific row indices to download. If None, download all rows. |\n",
       "| prepend_mdf5 | bool | True | If True, prepend 'md5:' to the checksums. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### download_dataset_from_csv\n",
       "\n",
       ">      download_dataset_from_csv (csv_file, base_url, output_dir,\n",
       ">                                 processor=None, rows=None, prepend_mdf5=True)\n",
       "\n",
       "Download a dataset using Pooch and save it to the specified output directory, reading file names and checksums from a CSV file.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| csv_file |  |  | Path to the CSV file containing file names and checksums. |\n",
       "| base_url |  |  | The base URL from which the files will be downloaded. |\n",
       "| output_dir |  |  | The directory where the downloaded files will be saved. |\n",
       "| processor | NoneType | None | A function to process the downloaded data. |\n",
       "| rows | NoneType | None | Specific row indices to download. If None, download all rows. |\n",
       "| prepend_mdf5 | bool | True | If True, prepend 'md5:' to the checksums. |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(download_dataset_from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has been successfully downloaded and saved to: ./_test_folder\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory where you want to save the downloaded files\n",
    "output_directory = \"./_test_folder\"\n",
    "# Define the base URL for the MSD dataset\n",
    "base_url = 'https://s3.ap-northeast-1.wasabisys.com/gigadb-datasets/live/pub/10.5524/100001_101000/100888/'\n",
    "\n",
    "download_dataset_from_csv('./data_examples/FMD_dataset_info.csv', base_url, output_directory, rows=[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data via Quilt/T4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allen Institute Cell Science (AICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### aics_pipeline\n",
       "\n",
       ">      aics_pipeline (n_images_to_download=40, image_save_dir=None,\n",
       ">                     col='SourceReadPath')\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n_images_to_download | int | 40 | Number of images to download |\n",
       "| image_save_dir | NoneType | None | Directory to save the images |\n",
       "| col | str | SourceReadPath | Column name for image paths in the data manifest |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### aics_pipeline\n",
       "\n",
       ">      aics_pipeline (n_images_to_download=40, image_save_dir=None,\n",
       ">                     col='SourceReadPath')\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n_images_to_download | int | 40 | Number of images to download |\n",
       "| image_save_dir | NoneType | None | Directory to save the images |\n",
       "| col | str | SourceReadPath | Column name for image paths in the data manifest |"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(aics_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading manifest: 100%|██████████| 77165/77165 [00:01<00:00, 45.2k/s]\n"
     ]
    }
   ],
   "source": [
    "image_target_paths, data_manifest = aics_pipeline(1, \"../_data/aics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../_data/aics/9e5d8f2e_3500001004_100X_20170623_5-Scene-1-P24-E06.czi_nucWholeIndexImageScale.tiff', '../_data/aics/77a69ff1_3500001004_100X_20170623_5-Scene-3-P26-F05.czi_nucWholeIndexImageScale.tiff']\n"
     ]
    }
   ],
   "source": [
    "print(image_target_paths)\n",
    "data_manifest.to_csv('../_data/aics/aics_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading manifest: 100%|██████████| 77165/77165 [00:01<00:00, 46.5k/s]\n",
      "100%|██████████| 491k/491k [00:02<00:00, 171kB/s] \n"
     ]
    }
   ],
   "source": [
    "image_target_paths, data_manifest = aics_pipeline(1, \"../_data/aics\", col=\"NucleusSegmentationReadPath\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities to make a list of all of the files of the train and test dataset in csv form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### manifest2csv\n",
       "\n",
       ">      manifest2csv (signal, target, paths=None, train_fraction=0.8,\n",
       ">                    data_save_path='./', train='train.csv', test='test.csv',\n",
       ">                    identifier=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| signal |  |  | List of paths to signal images |\n",
       "| target |  |  | List of paths to target images |\n",
       "| paths | NoneType | None | List of paths to images |\n",
       "| train_fraction | float | 0.8 | Fraction of data to use for training |\n",
       "| data_save_path | str | ./ | Path to save the CSV files |\n",
       "| train | str | train.csv | Name of the training CSV file |\n",
       "| test | str | test.csv | Name of the test CSV file |\n",
       "| identifier | NoneType | None | Identifier to add to the paths |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### manifest2csv\n",
       "\n",
       ">      manifest2csv (signal, target, paths=None, train_fraction=0.8,\n",
       ">                    data_save_path='./', train='train.csv', test='test.csv',\n",
       ">                    identifier=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| signal |  |  | List of paths to signal images |\n",
       "| target |  |  | List of paths to target images |\n",
       "| paths | NoneType | None | List of paths to images |\n",
       "| train_fraction | float | 0.8 | Fraction of data to use for training |\n",
       "| data_save_path | str | ./ | Path to save the CSV files |\n",
       "| train | str | train.csv | Name of the training CSV file |\n",
       "| test | str | test.csv | Name of the test CSV file |\n",
       "| identifier | NoneType | None | Identifier to add to the paths |"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(manifest2csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "manifest2csv(data_manifest[\"ChannelNumberBrightfield\"],data_manifest[\"ChannelNumber405\"], image_target_paths, data_save_path='./data_examples/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### split_dataframe\n",
       "\n",
       ">      split_dataframe (input_data, train_fraction=0.7, valid_fraction=0.1,\n",
       ">                       split_column=None, stratify=False, add_is_valid=False,\n",
       ">                       train_path='train.csv', test_path='test.csv',\n",
       ">                       valid_path='valid.csv', data_save_path=None)\n",
       "\n",
       "Splits a DataFrame or CSV file into train, test, and optional validation sets.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| input_data |  |  | Path to CSV file or DataFrame |\n",
       "| train_fraction | float | 0.7 | Proportion of data to use for the training set |\n",
       "| valid_fraction | float | 0.1 | Proportion of data to use for the validation set |\n",
       "| split_column | NoneType | None | Column name that indicates pre-defined split |\n",
       "| stratify | bool | False | If True, stratify by split_column during random split |\n",
       "| add_is_valid | bool | False | If True, adds 'is_valid' column in the train set to mark validation samples |\n",
       "| train_path | str | train.csv | Path to save the training CSV file |\n",
       "| test_path | str | test.csv | Path to save the test CSV file |\n",
       "| valid_path | str | valid.csv | Path to save the validation CSV file |\n",
       "| data_save_path | NoneType | None | Path to save the data files |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### split_dataframe\n",
       "\n",
       ">      split_dataframe (input_data, train_fraction=0.7, valid_fraction=0.1,\n",
       ">                       split_column=None, stratify=False, add_is_valid=False,\n",
       ">                       train_path='train.csv', test_path='test.csv',\n",
       ">                       valid_path='valid.csv', data_save_path=None)\n",
       "\n",
       "Splits a DataFrame or CSV file into train, test, and optional validation sets.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| input_data |  |  | Path to CSV file or DataFrame |\n",
       "| train_fraction | float | 0.7 | Proportion of data to use for the training set |\n",
       "| valid_fraction | float | 0.1 | Proportion of data to use for the validation set |\n",
       "| split_column | NoneType | None | Column name that indicates pre-defined split |\n",
       "| stratify | bool | False | If True, stratify by split_column during random split |\n",
       "| add_is_valid | bool | False | If True, adds 'is_valid' column in the train set to mark validation samples |\n",
       "| train_path | str | train.csv | Path to save the training CSV file |\n",
       "| test_path | str | test.csv | Path to save the test CSV file |\n",
       "| valid_path | str | valid.csv | Path to save the validation CSV file |\n",
       "| data_save_path | NoneType | None | Path to save the data files |"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(split_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### add_columns_to_csv\n",
       "\n",
       ">      add_columns_to_csv (csv_path, column_data, output_path=None)\n",
       "\n",
       "Adds one or more new columns to an existing CSV file.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| csv_path |  |  | Path to the input CSV file |\n",
       "| column_data |  |  | Dictionary of column names and values to add. Each value can be a scalar (single value for all rows) or a list matching the number of rows. |\n",
       "| output_path | NoneType | None | Path to save the updated CSV file. If None, it overwrites the input CSV file. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### add_columns_to_csv\n",
       "\n",
       ">      add_columns_to_csv (csv_path, column_data, output_path=None)\n",
       "\n",
       "Adds one or more new columns to an existing CSV file.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| csv_path |  |  | Path to the input CSV file |\n",
       "| column_data |  |  | Dictionary of column names and values to add. Each value can be a scalar (single value for all rows) or a list matching the number of rows. |\n",
       "| output_path | NoneType | None | Path to save the updated CSV file. If None, it overwrites the input CSV file. |"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(add_columns_to_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
